{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nFitting of the MLFM-MixSA Model 2\n=================================\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nimport matplotlib.pyplot as plt\nfrom pydygp.linlatentforcemodels import MLFMSAMix\nfrom sklearn.gaussian_process.kernels import RBF\nfrom pydygp.probabilitydistributions import Normal\nfrom pydygp.liealgebras import so\nnp.set_printoptions(precision=3, suppress=True)\n\nmlfm = MLFMSAMix(so(3), R=1, order=4, lf_kernels=[RBF(), ])\n\nx0 = np.eye(3) # inital conditions the std. basis vectors of R3\nN_repl = 3     # outputs of the experiment\n\nbeta = np.random.normal(size=6).reshape(2, 3)\nbeta /= np.linalg.norm(beta, axis=1)[:, None]\n#beta = np.array([[0., 0., 0.],\n#                 [-0.5, 0.31, 0.11]])\n\ntt = np.linspace(0., 2., 5)\n\nData, gtrue = mlfm.sim(x0, tt, beta=beta, size=N_repl)\nexperiments = [(tt, y) for y in Data]\n\n# setup the time vectors and augment them so maximum\n# time step is h\nmlfm._setup_times([tt]*N_repl, h=None)\n\n# indicies in complete time vector of the initial value problem\n#  -> super ugly and hacky at the moment\n#_ifix = np.linspace(0, tt.size-1, 3, dtype=np.intp)\n#_ifix = [tt.size // 3, 2*tt.size // 3]\n#ifix = [mlfm.data_inds[0][i] for i in _ifix]\n\n\nmu_ivp = np.array([d[_ifix, :] for d in Data])\n\nimport time\n# Model fitting\nbeta_prior = Normal(scale=5.)*6\nt0 = time.time()\ng, beta_,r  = mlfm.fit(experiments, ifix,\n                       beta0=beta, beta_is_fixed=False,\n                       beta_prior=beta_prior,\n                       mu_ivp_is_fixed=True, mu_ivp0=mu_ivp)\nt1 = time.time()\nprint(\"Mixture model took {}\".format(t1-t0))\n\n\nfrom pydygp.linlatentforcemodels import MLFMAdapGrad\nprint(\"Starting AG fit...\")\ntstart = time.time()\nY = np.column_stack((y.T.ravel() for y in Data))\nmlfmag = MLFMAdapGrad(so(3), R=1, lf_kernels=[RBF(), ])\nres_ag = mlfmag.fit(tt, Y, beta0=beta, beta_is_fixed=False,\n                    beta_prior=beta_prior,\n                    logpsi_is_fixed=True, logtau_is_fixed=True,\n                    optim_options={'disp': True,})\nprint(res_ag.optimres.nfev, res_ag.optimres.nit)\ntstop = time.time()\nprint(\"... Done. {}\".format(tstop-tstart))\n\nfrom pydygp.linlatentforcemodels import MLFMSA\nobj = MLFMSA(so(3), R=1, lf_kernels=[RBF(),], order=3)\nobj._setup_times([tt]*N_repl, h=.25, multi_output=True)\nobj.y_train_ = [d.T.ravel() for d in Data]\nbasis_funcs = [(lambda x, t0: (x-t0)**2, )]*len(ifix)\nobj._setup_softmax(ifix, basis_funcs)\nv = [-.0]*len(ifix)\nalf = 2000\npi = [obj.softmax_activs(v, x[:, None]) for x in obj.x_train_]\nr = [p.copy() for p in pi]\n\"\"\"\nprint(\"Start mixture fit...\")\ntstart = time.time()\nghat = gtrue[0](obj.ttc) #\nfor nt in range(5):\n    ghat, mu_ivp = obj._optim_g(ghat, beta, mu_ivp, alf, r, ifix, None)\n    pi = sum(np.mean(rm, axis=0) for rm in r) / len(r)\n    pi = [np.row_stack([np.mean(rm, axis=0)]*rm.shape[0])\n          for rm in r]\n    # update repsonsibilitees\n    r = obj._get_responsibilities(pi, ghat, beta, mu_ivp, alf, ifix)\n\nprint(\"-----\")\nprint(r[0].sum(axis=0))\nprint(np.mean(r[0], axis=0))\nprint(\"-----\")\ntstop = time.time()    \nprint(\"... Done. {}\".format(tstop-tstart))\n\"\"\"\n\nfig, ax = plt.subplots()\nax.plot(tt, g[mlfm.data_inds[0]], 'C0o')\nax.plot(mlfm.ttc, gtrue[0](mlfm.ttc), '-')\nax.plot(mlfmag.ttc, res_ag.g.T, 'ks')\n\n\nprint(\"=========================\")\nprint(beta)\nprint(beta_)\nprint(res_ag.beta)\n\ngmix = g[mlfm.data_inds[0]]\nAmix = [sum(brd*Ld for brd, Ld in zip(br, mlfm.basis_mats))\n            for br in beta_]\nAag = [sum(brd*Ld for brd, Ld in zip(br, mlfm.basis_mats))\n           for br in res_ag.beta]\nAtrue = [sum(brd*Ld for brd, Ld in zip(br, mlfm.basis_mats))\n         for br in beta]\n\na12 = Amix[0][0, 1] + Amix[1][0, 1] * gmix\na13 = Amix[0][0, 2] + Amix[1][0, 2] * gmix\na23 = Amix[0][1, 2] + Amix[1][1, 2] * gmix\n\nb12 = Aag[0][0, 1] + Aag[1][0, 1] * res_ag.g.ravel()\nb13 = Aag[0][0, 2] + Aag[1][0, 2] * res_ag.g.ravel()\nb23 = Aag[0][1, 2] + Aag[1][1, 2] * res_ag.g.ravel()\n\nc12 = Atrue[0][0, 1] + Atrue[1][0, 1] * gtrue[0](tt)\nc13 = Atrue[0][0, 2] + Atrue[1][0, 2] * gtrue[0](tt)\nc23 = Atrue[0][1, 2] + Atrue[1][1, 2] * gtrue[0](tt)\n\nfig, ax = plt.subplots()\nax.plot(tt, a13, label=r'$a_{13}$ mix')\nax.plot(tt, b13, '--', label=r'$a_{13}$ ag')\nax.plot(tt, c13, label=r'$a_{13}$ true')\nax.legend()\n\nfig, ax = plt.subplots()\nax.plot(tt, a12, label=r'$a_{12}$ mix')\nax.plot(tt, b12, label=r'$a_{12}$ ag')\nax.plot(tt, c12, label=r'$a_{12}$ true')\nax.legend()\n\nfig, ax = plt.subplots()\nax.plot(tt, a23, label=r'$a_{23}$ mix')\nax.plot(tt, b23, label=r'$a_{23}$ ag')\nax.plot(tt, c23, label=r'$a_{23}$ true')\nax.legend()\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}