{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nVariational Inference\n=====================\n\nThis example presents an illustration of using the MLFM to\nlearn the model\n\n\\begin{align}\\dot{\\mathbf{x}}(t) = \\mathbf{A}(t)\\mathbf{x}(t)\\end{align}\n\nwhere $A(t) \\in \\mathfrak{so}(3)$ and $\\| x_0 \\| = 1$.\n\nThis note will also demonstrate the process of holding certain variables\nfixed as well as defining priors\n\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\nimport numpy as np\nfrom pydygp.probabilitydistributions import (GeneralisedInverseGaussian,\n                                             InverseGamma,\n                                             Normal)\nfrom sklearn.gaussian_process.kernels import RBF\nfrom pydygp.liealgebras import so\nfrom pydygp.linlatentforcemodels import (MLFMAdapGrad,\n                                         GibbsMLFMAdapGrad,\n                                         VarMLFMAdapGrad)\nnp.random.seed(15)\nnp.set_printoptions(precision=3, suppress=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Our first step is to initialise the models and then simulate some data.\n\nMake the model\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "vmlfm = VarMLFMAdapGrad(so(3), R=1, lf_kernels=[RBF(),])\ngmlfm = GibbsMLFMAdapGrad(so(3), R=1, lf_kernels=[RBF(),])\n\nbeta = np.row_stack(([0.]*3,\n                     np.random.normal(size=3)))\n\n# simulate some initial conditions\nx0 = np.random.normal(size=6).reshape(2, 3)\nx0 /= np.linalg.norm(x0, axis=1)[:, None]\n\n# Time points to solve the model at\ntt = np.linspace(0., 6, 7)\n\n# Data and true forces\nData, g0 = vmlfm.sim(x0, tt, beta=beta, size=2)\n# vectorised and stack the data\nY = np.column_stack((y.T.ravel() for y in Data))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Specifying priors\n-----------------\n.. currentmodule:: pydygp.probabilitydistributions\n\nThe prior should have a loglikelihood(x, eval_gradient=False) method\nwhich returns the loglikelihood of the prior variable at x and\nand optionally its gradient.\n\nPreexisting priors are contained in :py:mod:`pydygp.probabilitydistributions`\n\nfor example there is the class `ProbabilityDistribution`\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "logpsi_prior = GeneralisedInverseGaussian(a=5, b=5, p=-1).logtransform()\nloggamma_prior = InverseGamma(a=0.001, b=0.001).logtransform()*vmlfm.dim.K\n\nbeta_prior = Normal(scale=1.) * beta.size\n\nfitopts = {'logpsi_is_fixed': True, 'logpsi_prior': logpsi_prior,\n           'loggamma_is_fixed': True, 'loggamma_prior': loggamma_prior,\n           'beta_is_fixed': True, 'beta_prior': beta_prior,\n           'beta0': beta,\n           }\n\n# Fit the model\nres, Eg, Covg, _, _ = vmlfm.varfit(tt, Y, **fitopts)\n\n\nGrv = gmlfm.gibbsfit(tt, Y, **fitopts, mapres=res)\n\nmg, cg = gmlfm.g_condpdf_mo(Y, beta,\n                            logphi=res.logphi,\n                            logpsi=res.logpsi,\n                            gamma=np.exp(res.loggamma))\n\nLapcov = res.optimres.hess_inv[:vmlfm.dim.N*vmlfm.dim.R,\n                               :vmlfm.dim.N*vmlfm.dim.R]\n\nfig, ax = plt.subplots()\n#ax.plot(tt, res.g.T, '+')\nax.plot(tt, Grv['g'].T, 'k+', alpha=0.2)\n#ax.plot(tt, Eg, 'o')\n#ax.errorbar(tt, res.g.T, yerr = 2*np.sqrt(np.diag(Lapcov)), fmt='s')\n#ax.errorbar(tt, Eg, yerr = 2*np.sqrt(np.diag(Covg[..., 0, 0])), fmt='o')\n\nttdense = np.linspace(0., tt[-1])\nax.plot(ttdense, g0[0](ttdense), 'k-', alpha=0.2)\nfpred, fstd = vmlfm.predict_lf(ttdense, return_std=True)\nvfpred, fstd2 = vmlfm.var_predict_lf(ttdense, True)\nvfpred, fstd3 = vmlfm.var_predict_lf(ttdense, True)\nax.plot(ttdense, vfpred[0, :], 'r--')\n\nax.fill_between(ttdense,\n                fpred[0, :] + 2*fstd[0, :],\n                fpred[0, :] - 2*fstd[0, :],\n                alpha=0.3)\n\n#gp = vmlfm.latentforces[0]\n#M = gp.kernel_(ttdense[:, None], vmlfm.ttc[:, None])\n#M = M.dot(np.linalg.inv(gp.kernel_(vmlfm.ttc[:, None])))\n#C = M.dot(Covg[..., 0, 0].dot(M.T))\n#sd = np.sqrt(np.diag(C))\n\nax.fill_between(ttdense,\n                vfpred[0, :] + 2*fstd3[0, :],\n                vfpred[0, :] - 2*fstd3[0, :],\n                facecolor='red',\n                alpha=0.3)\n\nprint(cg.shape)\nfig, ax = plt.subplots()\n\nax.errorbar(tt, mg, yerr=2*np.sqrt(np.diag(cg)), xerr=None, capsize=20)\n\nax.plot(ttdense, g0[0](ttdense), 'k-', alpha=0.2)\nax.plot(ttdense, vfpred[0, :], 'r-')\n\nax.fill_between(ttdense,\n                vfpred[0, :] + 2*fstd3[0, :],\n                vfpred[0, :] - 2*fstd3[0, :],\n                facecolor='red',\n                alpha=0.2)\n\nplt.show()\n\n\n\n\"\"\"\nttdense = np.linspace(tt[0], tt[-1], 50)\nCff_ = vmlfm.latentforces[0].kernel_(ttdense[:, None], tt[:, None])\nCf_f_ = vmlfm.latentforces[0].kernel_(tt[:, None])\nCf_f_[np.diag_indices_from(Cf_f_)] += 1e-5\nLf_f_ = np.linalg.cholesky(Cf_f_)\n\nfrom scipy.linalg import cho_solve\ngpred = Cff_.dot(cho_solve((Lf_f_, True), Eg))\nprint(np.sqrt(np.diag(Covg[..., 0, 0])))\nax.plot(ttdense, gpred, 'r-.')\n\"\"\""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}