

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Approximate Density &mdash; pydygp  documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/gallery.css" type="text/css" />
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Gallery of Examples" href="../../auto_examples/index.html" />
    <link rel="prev" title="Successive Approximations" href="index.html" /> 

  
  <script src="../../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../../index.html" class="icon icon-home"> pydygp
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../install.html">Installing PydyGP</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../index.html">PydyGP Tutorial</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="../mlfm.html">Multiplicative Latent Force Models Tutorial</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="../mlfm.html#model-description">Model Description</a></li>
<li class="toctree-l3 current"><a class="reference internal" href="../mlfm.html#model-fitting">Model Fitting</a><ul class="current">
<li class="toctree-l4"><a class="reference internal" href="../mlfm_adapgrad_tutorials/index.html">Adaptive Gradient Matching Methods</a></li>
<li class="toctree-l4 current"><a class="reference internal" href="index.html">Successive Approximations</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../mlfm.html#adaptive-gradient-matching">Adaptive Gradient Matching</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../auto_examples/index.html">Gallery of Examples</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../_autosummary/pydygp.linlatentforcemodels.html">pydygp.linlatentforcemodels</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../_autosummary/pydygp.probabilitydistributions.html">pydygp.probabilitydistributions</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">pydygp</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../index.html">Docs</a> &raquo;</li>
        
          <li><a href="../index.html">PydyGP Tutorial</a> &raquo;</li>
        
          <li><a href="../mlfm.html">Multiplicative Latent Force Models Tutorial</a> &raquo;</li>
        
          <li><a href="index.html">Successive Approximations</a> &raquo;</li>
        
      <li>Approximate Density</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../../_sources/tutorials/mlfm_sa_tutorials/plot_mlfmsa_kf.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="sphx-glr-download-link-note admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Click <a class="reference internal" href="#sphx-glr-download-tutorials-mlfm-sa-tutorials-plot-mlfmsa-kf-py"><span class="std std-ref">here</span></a> to download the full example code</p>
</div>
<div class="sphx-glr-example-title section" id="approximate-density">
<span id="sphx-glr-tutorials-mlfm-sa-tutorials-plot-mlfmsa-kf-py"></span><h1>Approximate Density<a class="headerlink" href="#approximate-density" title="Permalink to this headline">¶</a></h1>
<p>When using the method of successive approximation we construct
a regression model</p>
<div class="math notranslate nohighlight">
\[p(\mathbf{x} \mid \mathbf{g}, \boldsymbol{\beta})
= \mathcal{N}(
\mathbf{x}
\mid \mathbf{P}^{M} \boldsymbol{\mu}_0,
\alpha \mathbf{I})\]</div>
<p>The idea is to construct an approximation to this density by
introduction each of the successive approximations</p>
<div class="math notranslate nohighlight">
\[\mathbf{z}_{i} = \mathbf{P}\mathbf{z}_{i-1},\]</div>
<p>the idea being that knowing the complete set of approximations
<span class="math notranslate nohighlight">\(\{ z_0,\ldots,z_M\}\)</span> we can solve for the latent variables
by rearranging the linear equations, instead of manipulating the
polynomial mean function.</p>
<p>For this conversion to work we need to introduce a regularisation
parameter <span class="math notranslate nohighlight">\(\lambda &gt; 0\)</span> and then define <span class="math notranslate nohighlight">\(\mathcal{N}(
\mathbf{z}_{i} \mid \mathbf{P}\mathbf{z}_{i-1}, \lambda
\mathbf{I})\)</span>, once we do this we can write log-likelihood of the
state variables</p>
<div class="math notranslate nohighlight">
\[\log = -\frac{\lambda}{2} \sum_{i=1}^{M}
\left(
\mathbf{z}_{i-1}^{\top}\mathbf{P}^{\top}\mathbf{P}\mathbf{z}_{i-1}
- 2\mathbf{z}_{i}^{\top}\mathbf{P}\mathbf{z}_{i-1}
\right)\]</div>
<p>Now the matrices <span class="math notranslate nohighlight">\(\mathbf{P}\)</span> are linear in the parameters
which means that after vectorisation they can be represented as</p>
<div class="math notranslate nohighlight">
\[\operatorname{vec}(\mathbf{P}) = \mathbf{V}\mathbf{g} + \mathbf{v}_0\]</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">The matrices <span class="math notranslate nohighlight">\(\mathbf{P}\)</span> and their affine representations are
most easily written compactly using kronecker products, unfortunately
these are not necessarily the best computational representations and
there is a lot here that needs refining.</p>
</div>
<div class="section" id="linear-gaussian-model">
<h2>Linear Gaussian Model<a class="headerlink" href="#linear-gaussian-model" title="Permalink to this headline">¶</a></h2>
<p>We take a break in the model to now discuss how to start putting some
of the ideas discussed above into code. For the Kalman Filter we are
going to use the code in the
<a class="reference external" href="https://pykalman.github.io/">PyKalman package</a>, but hacked a little
bit to allow for filtering and smoothing of independent sequences
with a common transition matrix.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">pydygp.liealgebras</span> <span class="kn">import</span> <span class="n">so</span>
<span class="kn">from</span> <span class="nn">sklearn.gaussian_process.kernels</span> <span class="kn">import</span> <span class="n">RBF</span>
<span class="kn">from</span> <span class="nn">pydygp.linlatentforcemodels</span> <span class="kn">import</span> <span class="n">MLFMSA</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">123</span><span class="p">)</span>

<span class="n">mlfm</span> <span class="o">=</span> <span class="n">MLFMSA</span><span class="p">(</span><span class="n">so</span><span class="p">(</span><span class="mi">3</span><span class="p">),</span> <span class="n">R</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">lf_kernels</span><span class="o">=</span><span class="p">[</span><span class="n">RBF</span><span class="p">(),</span> <span class="p">],</span> <span class="n">order</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">beta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
                 <span class="p">[</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.31</span><span class="p">,</span> <span class="mf">0.11</span><span class="p">]])</span>
<span class="n">tt</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">6.</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>
<span class="n">x0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="n">Data</span><span class="p">,</span> <span class="n">g</span> <span class="o">=</span> <span class="n">mlfm</span><span class="o">.</span><span class="n">sim</span><span class="p">(</span><span class="n">x0</span><span class="p">,</span> <span class="n">tt</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="n">beta</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="expectation-maximisation">
<h2>Expectation Maximisation<a class="headerlink" href="#expectation-maximisation" title="Permalink to this headline">¶</a></h2>
<p>So we have introduced a large collection of unintersting latent variables,
the set of successive approximations <span class="math notranslate nohighlight">\(\{ z_0, \ldots, z_M \}\)</span>, and
so we need to integrate them out. If we define the statistics</p>
<div class="math notranslate nohighlight">
\[\boldsymbol{\Psi}_0 = \sum_{i=1}^{M} \langle \mathbf{z}_{i-1}
\mathbf{z}_{i-1}^{\top} \rangle_{q(Z)}, \quad
\boldsymbol{\Psi}_1 = \sum_{i=1}^{M} \langle \mathbf{z}_{i}
\mathbf{z}_{i-1}^{\top} \rangle_{q(Z)}\]</div>
<p>Then the objective function of the <cite>M-step</cite> becomes</p>
<div class="math notranslate nohighlight">
\[Q(\mathbf{g}, \mathbf{g}^{old}) =
-\frac{1}{2} \mathbf{g}^{\top}
\left( \mathbf{V}^{\top}
(\boldsymbol{\Psi}_0 \otimes \mathbf{I}_{NK})\mathbf{V} +
\lambda^{-1} \mathbf{C}^{-1} \right)\mathbf{g} - 2\]</div>
<p>More sensible place to start – the Kalman Filter performs the numerical integration</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pydygp.linlatentforcemodels</span> <span class="kn">import</span> <span class="n">KalmanFilter</span>

<span class="n">mlfm</span><span class="o">.</span><span class="n">_setup_times</span><span class="p">(</span><span class="n">tt</span><span class="p">,</span> <span class="n">h</span><span class="o">=.</span><span class="mi">25</span><span class="p">)</span>
<span class="c1">#ifx = mlfm.ttc // 2 # index left fixed by the Picard iteration</span>

<span class="n">ifx</span> <span class="o">=</span> <span class="mi">0</span>

<span class="n">A</span> <span class="o">=</span> <span class="n">mlfm</span><span class="o">.</span><span class="n">_K</span><span class="p">(</span><span class="n">g</span><span class="p">[</span><span class="mi">0</span><span class="p">](</span><span class="n">mlfm</span><span class="o">.</span><span class="n">ttc</span><span class="p">),</span> <span class="n">beta</span><span class="p">,</span> <span class="n">ifx</span><span class="p">)</span>

<span class="n">init_conds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">y</span><span class="p">[</span><span class="n">ifx</span><span class="p">,</span> <span class="p">:]</span> <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">Data</span><span class="p">])</span>

<span class="n">Ndata</span> <span class="o">=</span> <span class="n">tt</span><span class="o">.</span><span class="n">size</span>

<span class="c1"># array [m0, m1, m2] with m0 = np.kron(Data[0][ifx, :], ones)</span>
<span class="n">init_vals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">kron</span><span class="p">(</span><span class="n">init_conds</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">Ndata</span><span class="p">))</span><span class="o">.</span><span class="n">T</span>
<span class="n">init_state_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">kron</span><span class="p">(</span><span class="n">init_conds</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">mlfm</span><span class="o">.</span><span class="n">dim</span><span class="o">.</span><span class="n">N</span><span class="p">))</span><span class="o">.</span><span class="n">T</span>
<span class="n">final_vals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">column_stack</span><span class="p">([</span><span class="n">y</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span> <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">Data</span><span class="p">])</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ma</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">mlfm</span><span class="o">.</span><span class="n">order</span><span class="p">,</span> <span class="p">)</span> <span class="o">+</span> <span class="n">init_vals</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>  <span class="c1"># data we are going to give to the KalmanFilter</span>
<span class="n">X</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="o">...</span><span class="p">]</span> <span class="o">=</span> <span class="n">init_vals</span>
<span class="n">X</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">mlfm</span><span class="o">.</span><span class="n">order</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">...</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ma</span><span class="o">.</span><span class="n">masked</span>  <span class="c1"># mask these values -- we have no data</span>
<span class="n">X</span><span class="p">[</span><span class="n">mlfm</span><span class="o">.</span><span class="n">order</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">...</span><span class="p">]</span> <span class="o">=</span> <span class="n">final_vals</span>

<span class="n">NK</span> <span class="o">=</span> <span class="n">mlfm</span><span class="o">.</span><span class="n">dim</span><span class="o">.</span><span class="n">N</span><span class="o">*</span><span class="n">mlfm</span><span class="o">.</span><span class="n">dim</span><span class="o">.</span><span class="n">K</span>
<span class="c1">#observation_matrices = np.array([np.eye(NK)]*3)</span>
<span class="n">C</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">Ndata</span><span class="o">*</span><span class="mi">3</span><span class="p">,</span> <span class="n">mlfm</span><span class="o">.</span><span class="n">dim</span><span class="o">.</span><span class="n">N</span><span class="o">*</span><span class="n">mlfm</span><span class="o">.</span><span class="n">dim</span><span class="o">.</span><span class="n">K</span><span class="p">))</span>
<span class="n">_inds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">mlfm</span><span class="o">.</span><span class="n">data_inds</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">k</span><span class="o">*</span><span class="n">mlfm</span><span class="o">.</span><span class="n">dim</span><span class="o">.</span><span class="n">N</span>
                        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">mlfm</span><span class="o">.</span><span class="n">dim</span><span class="o">.</span><span class="n">K</span><span class="p">)])</span>
<span class="n">C</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">Ndata</span><span class="o">*</span><span class="n">mlfm</span><span class="o">.</span><span class="n">dim</span><span class="o">.</span><span class="n">K</span><span class="p">),</span> <span class="n">_inds</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
<span class="n">observation_matrices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">C</span><span class="p">,</span> <span class="p">]</span><span class="o">*</span><span class="mi">3</span><span class="p">)</span>

<span class="n">kf</span> <span class="o">=</span> <span class="n">KalmanFilter</span><span class="p">(</span><span class="n">initial_state_mean</span><span class="o">=</span><span class="n">init_state_mean</span><span class="p">,</span>
                  <span class="n">initial_state_covariance</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">NK</span><span class="p">)</span><span class="o">*</span><span class="mf">1e-5</span><span class="p">,</span>
                  <span class="n">observation_offsets</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">mlfm</span><span class="o">.</span><span class="n">order</span><span class="p">,</span> <span class="n">Ndata</span><span class="o">*</span><span class="mi">3</span><span class="p">,</span> <span class="n">mlfm</span><span class="o">.</span><span class="n">dim</span><span class="o">.</span><span class="n">K</span><span class="p">)),</span>
                  <span class="n">observation_matrices</span><span class="o">=</span><span class="n">observation_matrices</span><span class="p">,</span>
                  <span class="n">transition_matrices</span><span class="o">=</span><span class="n">A</span><span class="p">,</span>
                  <span class="n">transition_covariance</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">NK</span><span class="p">)</span><span class="o">*</span><span class="mf">1e-5</span><span class="p">,</span>
                  <span class="n">transition_offsets</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">init_vals</span><span class="o">.</span><span class="n">shape</span><span class="p">),</span>
                  <span class="n">n_dim_state</span><span class="o">=</span><span class="n">NK</span><span class="p">,</span>
                  <span class="n">n_dim_obs</span><span class="o">=</span><span class="n">Ndata</span><span class="o">*</span><span class="mi">3</span><span class="p">)</span>

<span class="n">means</span><span class="p">,</span> <span class="n">covs</span><span class="p">,</span> <span class="n">k_gains</span> <span class="o">=</span> <span class="n">kf</span><span class="o">.</span><span class="n">smooth</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">mean</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">means</span><span class="p">):</span>
    <span class="c1"># unvectorise the column</span>
    <span class="n">m</span> <span class="o">=</span> <span class="n">mean</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">mlfm</span><span class="o">.</span><span class="n">dim</span><span class="o">.</span><span class="n">K</span><span class="p">,</span> <span class="n">mlfm</span><span class="o">.</span><span class="n">dim</span><span class="o">.</span><span class="n">N</span><span class="p">))</span><span class="o">.</span><span class="n">T</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">mlfm</span><span class="o">.</span><span class="n">ttc</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="s1">&#39;k-&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">/</span><span class="n">mlfm</span><span class="o">.</span><span class="n">order</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">tt</span><span class="p">,</span> <span class="n">Data</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="s1">&#39;ks&#39;</span><span class="p">)</span>
</pre></div>
</div>
<img alt="../../_images/sphx_glr_plot_mlfmsa_kf_001.png" class="sphx-glr-single-img" src="../../_images/sphx_glr_plot_mlfmsa_kf_001.png" />
<p>So the linear model seems to be performing the forward iteration in a
reasonable way. The next challenge is to iry and invert this for the
conditional distribution.</p>
<p>The relevant objective function is</p>
<div class="math notranslate nohighlight">
\[\left(
\operatorname{vec}(\mathbf{P})^{\top}
\left(\boldsymbol{\Psi}_0 \otimes \lambda \cdot \mathbf{I} \right)
\operatorname{vec}(\mathbf{P})
+ \mathbf{g}^{\top}\mathbf{C}_g^{-1}\mathbf{g}\right)
- 2 \lambda \operatorname{vec}(\boldsymbol{\Psi}_1)^{\top}
\operatorname{vec}(\mathbf{P})\]</div>
<p>So the first thing we need is a function that constructs these statistics</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">_get_kf_statistics</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">kf</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; Gets</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># the mean, cov and kalman gain matrix</span>
    <span class="n">means</span><span class="p">,</span> <span class="n">covs</span><span class="p">,</span> <span class="n">kalman_gains</span> <span class="o">=</span> <span class="n">kf</span><span class="o">.</span><span class="n">smooth</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="c1"># pairwise cov between Cov{ z[i], z[i-1]</span>
    <span class="c1"># note pairwise_covs[0] = 0  - it gets ignored</span>
    <span class="n">pairwise_covs</span> <span class="o">=</span> <span class="n">kf</span><span class="o">.</span><span class="n">_smooth_pair</span><span class="p">(</span><span class="n">covs</span><span class="p">,</span> <span class="n">kalman_gains</span><span class="p">)</span>

    <span class="n">S0</span> <span class="o">=</span> <span class="mf">0.</span>
    <span class="k">for</span> <span class="n">m</span><span class="p">,</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">means</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">covs</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]):</span>
        <span class="n">S0</span> <span class="o">+=</span> <span class="n">c</span> <span class="o">+</span> \
              <span class="p">(</span><span class="n">m</span><span class="p">[:,</span> <span class="bp">None</span><span class="p">,</span> <span class="p">:]</span> <span class="o">*</span> <span class="n">m</span><span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="o">...</span><span class="p">])</span><span class="o">.</span><span class="n">transpose</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">S1</span> <span class="o">=</span> <span class="mf">0.</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">pw</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">pairwise_covs</span><span class="p">[</span><span class="mi">1</span><span class="p">:]):</span>
        <span class="n">S1</span> <span class="o">+=</span> <span class="n">pw</span> <span class="o">+</span> \
              <span class="p">(</span><span class="n">means</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">][:,</span> <span class="bp">None</span><span class="p">,</span> <span class="p">:]</span> <span class="o">*</span> \
               <span class="n">means</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="bp">None</span><span class="p">,</span> <span class="o">...</span><span class="p">])</span><span class="o">.</span><span class="n">transpose</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">S0</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">S1</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
<p>Now we need a function that takes those created statistics and turns
returns an estimate of the latent forces</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scipy.linalg</span> <span class="kn">import</span> <span class="n">block_diag</span><span class="p">,</span> <span class="n">cho_solve</span>
<span class="k">def</span> <span class="nf">kron_A_N</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">N</span><span class="p">):</span>  <span class="c1"># Simulates np.kron(A, np.eye(N))</span>
    <span class="n">m</span><span class="p">,</span><span class="n">n</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">m</span><span class="p">,</span><span class="n">N</span><span class="p">,</span><span class="n">n</span><span class="p">,</span><span class="n">N</span><span class="p">),</span><span class="n">dtype</span><span class="o">=</span><span class="n">A</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
    <span class="n">r</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">N</span><span class="p">)</span>
    <span class="n">out</span><span class="p">[:,</span><span class="n">r</span><span class="p">,:,</span><span class="n">r</span><span class="p">]</span> <span class="o">=</span> <span class="n">A</span>
    <span class="n">out</span><span class="o">.</span><span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">m</span><span class="o">*</span><span class="n">N</span><span class="p">,</span><span class="n">n</span><span class="o">*</span><span class="n">N</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">out</span>


<span class="k">def</span> <span class="nf">bar</span><span class="p">(</span><span class="n">S0</span><span class="p">,</span> <span class="n">S1</span><span class="p">,</span> <span class="n">mlfm</span><span class="p">,</span> <span class="n">ifx</span><span class="p">,</span> <span class="n">lam</span><span class="o">=</span><span class="mf">1e5</span><span class="p">):</span>
    <span class="n">Cg</span> <span class="o">=</span> <span class="p">[</span><span class="n">gp</span><span class="o">.</span><span class="n">kernel</span><span class="p">(</span><span class="n">mlfm</span><span class="o">.</span><span class="n">ttc</span><span class="p">[:,</span> <span class="bp">None</span><span class="p">])</span>
          <span class="k">for</span> <span class="n">gp</span> <span class="ow">in</span> <span class="n">mlfm</span><span class="o">.</span><span class="n">latentforces</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">Cg</span><span class="p">:</span>
        <span class="n">c</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">diag_indices_from</span><span class="p">(</span><span class="n">c</span><span class="p">)]</span> <span class="o">+=</span> <span class="mf">1e-5</span>
        <span class="n">Lg</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">cholesky</span><span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">Cg</span><span class="p">]</span>
    <span class="n">invcov</span> <span class="o">=</span> <span class="n">block_diag</span><span class="p">(</span><span class="o">*</span><span class="p">[</span>
        <span class="n">cho_solve</span><span class="p">((</span><span class="n">L</span><span class="p">,</span> <span class="bp">True</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">mlfm</span><span class="o">.</span><span class="n">dim</span><span class="o">.</span><span class="n">N</span><span class="o">*</span><span class="n">mlfm</span><span class="o">.</span><span class="n">dim</span><span class="o">.</span><span class="n">R</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">L</span> <span class="ow">in</span> <span class="n">Lg</span><span class="p">])</span>

    <span class="n">V</span><span class="p">,</span> <span class="n">v</span> <span class="o">=</span> <span class="n">mlfm</span><span class="o">.</span><span class="n">_vecK_aff_rep</span><span class="p">(</span><span class="n">beta</span><span class="p">,</span> <span class="n">ifx</span><span class="p">)</span>
    <span class="n">S_x_I</span> <span class="o">=</span> <span class="n">kron_A_N</span><span class="p">(</span><span class="n">S0</span><span class="p">,</span> <span class="n">mlfm</span><span class="o">.</span><span class="n">dim</span><span class="o">.</span><span class="n">N</span><span class="o">*</span><span class="n">mlfm</span><span class="o">.</span><span class="n">dim</span><span class="o">.</span><span class="n">K</span><span class="p">)</span>
    <span class="c1">#S_x_I = np.kron(S0, np.eye(mlfm.dim.N*mlfm.dim.K))</span>
    <span class="n">invcov</span> <span class="o">+=</span> <span class="n">lam</span><span class="o">*</span><span class="n">V</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">S_x_I</span><span class="p">)</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">V</span><span class="p">)</span>
    <span class="n">cov</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">invcov</span><span class="p">)</span>
    <span class="n">premean</span> <span class="o">=</span> <span class="n">S1</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span> <span class="o">-</span> <span class="n">v</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">S_x_I</span><span class="p">)</span>
    <span class="n">premean</span> <span class="o">=</span> <span class="n">lam</span><span class="o">*</span><span class="n">premean</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">V</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">lstsq</span><span class="p">(</span><span class="n">invcov</span><span class="p">,</span> <span class="n">premean</span><span class="p">,</span> <span class="n">rcond</span><span class="o">=</span><span class="bp">None</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

<span class="n">S0</span><span class="p">,</span> <span class="n">S1</span> <span class="o">=</span> <span class="n">_get_kf_statistics</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">kf</span><span class="p">)</span>
<span class="n">ghat</span> <span class="o">=</span> <span class="n">bar</span><span class="p">(</span><span class="n">S0</span><span class="p">,</span> <span class="n">S1</span><span class="p">,</span> <span class="n">mlfm</span><span class="p">,</span> <span class="n">ifx</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">mlfm</span><span class="o">.</span><span class="n">ttc</span><span class="p">,</span> <span class="n">g</span><span class="p">[</span><span class="mi">0</span><span class="p">](</span><span class="n">mlfm</span><span class="o">.</span><span class="n">ttc</span><span class="p">),</span> <span class="s1">&#39;k-&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">mlfm</span><span class="o">.</span><span class="n">ttc</span><span class="p">,</span> <span class="n">ghat</span><span class="p">,</span> <span class="s1">&#39;+&#39;</span><span class="p">)</span>
</pre></div>
</div>
<img alt="../../_images/sphx_glr_plot_mlfmsa_kf_002.png" class="sphx-glr-single-img" src="../../_images/sphx_glr_plot_mlfmsa_kf_002.png" />
<p>So far this is of limit practical use, it allows us to recover the
force when we use the operator <span class="math notranslate nohighlight">\(\mathbf{P}\)</span> evaluated at the
true force. The next note in the series will consider extending this
to an iterative EM setting to discover the force.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<p><strong>Total running time of the script:</strong> ( 0 minutes  0.675 seconds)</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-tutorials-mlfm-sa-tutorials-plot-mlfmsa-kf-py">
<div class="sphx-glr-download docutils container">
<a class="reference download internal" href="../../_downloads/plot_mlfmsa_kf.py" download=""><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">plot_mlfmsa_kf.py</span></code></a></div>
<div class="sphx-glr-download docutils container">
<a class="reference download internal" href="../../_downloads/plot_mlfmsa_kf.ipynb" download=""><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">plot_mlfmsa_kf.ipynb</span></code></a></div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.readthedocs.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../../auto_examples/index.html" class="btn btn-neutral float-right" title="Gallery of Examples" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="index.html" class="btn btn-neutral" title="Successive Approximations" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2018, Daniel Tait.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../../',
            VERSION:'',
            LANGUAGE:'None',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="../../_static/jquery.js"></script>
      <script type="text/javascript" src="../../_static/underscore.js"></script>
      <script type="text/javascript" src="../../_static/doctools.js"></script>
      <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  <script type="text/javascript" src="../../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>