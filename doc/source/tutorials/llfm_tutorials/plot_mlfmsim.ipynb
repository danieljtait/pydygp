{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# MLFM Simulation\n\n\n.. currentmodule:: pydygp.linlatentforcemodels\n\nThis note describes the process of simulating the MLFM using any of the classes extending :class:`BaseMLFM`, this tutorial demonstrates the simulation process using this base class, but in practice it is the child classes along with their extended methods which will be most useful.\n\nBasic Model Setup\n=================\n\nThe MLFM is specifed by describing a set of $K \\times K$ square matrices $A_0, A_1, \\ldots,A_R$. We refer to the first matrix $A_0$ as the :code:`offset` and by default in initalisation of :class:`BaseMLFM` is taken to be zero and so we need only pass the set $A_1, \\ldots, A_R$ to the argument :code:`struct_mats`. Therefore to construct the ODE on the circle $S^1$ given by\n\n\\begin{align}\\begin{bmatrix} \\dot{x}(t) \\\\ \\dot{y}(t) \\end{bmatrix} =\n   g_1(t) \\cdot \\begin{bmatrix} 0 & - 1 \\\\ 1 & 0 \\end{bmatrix}\n   \\begin{bmatrix} x(t) \\\\ y(t) \\end{bmatrix}\\end{align}\n\n\nwe need to define the skew-symmetric matrix $L_1$ above, this can be done manually or by importing the :class:`liealgebras`. The following code block is enough to set up this model\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nimport matplotlib.pyplot as plt\nfrom pydygp.linlatentforcemodels import BaseMLFM\nfrom pydygp.liealgebras import so\n\n# equivalent to L1 = np.array([[0., -1.], [1., 0.]]), \nL1 = so(2)\n\nmlfm = BaseMLFM(L1, R=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Choice of kernel function\n~~~~~~~~~~~~~~~~~~~~~~~~~\n\nBecause we have not specified the :code:`lf_kernel` argument in the\ninitialisation of the MLFM object it will default to the Radial basis function\nkernel with multiplicative scale parameter given by\n\n\\begin{align}k(t, t') = \\\\theta_0 \\\\exp\\left\\\\{ -\\frac{(t-t')^2}{2\\theta_1^2} \\right\\\\}\\end{align}\n\nThis package has the scikit-learn parackage as a requirement and so we have\nthe luxury of being able to chose from any of the prexisting kernel functions\nimplemented in that package. The defaul behaviour is to use the RBF kernel above\nso that the following are equivalent\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from sklearn.gaussian_process.kernels import ConstantKernel, RBF\nkern = ConstantKernel() * RBF()  # equiv. to 1 * RBF()\n\nmlfm1 = BaseMLFM(L1, R=1)                  # These two models \nmlfm2 = BaseMLFM(L1, lf_kernels=(kern, ))  # are the same"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Simulation\n----------\nFor the simple model on the unit circle we have described above it is possible\nto simulate directly, this is not going to be true in general and so the\n:function:`.BaseMLFM.sim` implements a more general approach which may be\ndescribed as\n\n1. Simulate a dense realisation from the set of latent GPs\n2. Interpolate simulated GP draws with a cubic spline\n3. Use the smooth interpolating functions in a numerical ODE solver\n\nIn 1. we need to simulate the GP at a set of points dense enough so as to\nensure that  the conditional variance between the points is neglible and so\ntreat the function as being given exactly by the predicted mean. In principle\nwe could then pass the conditional mean function to the ODE integration routine,\nbut the predicted mean requires evaluating the kernel at the whole set of\ndense points points and so in practice it is more efficent to replace them with\na spline approximation which is quicker to evaluate. We also need the \nsmoothly interpolated functions because the :module:`odeint` routine uses\nadaptive methods so we cannot guarantee beforehand the set of time points at\nwhich the evolution equation will be evaluated.\n\nThe simulation function returns the data at the requested set of points, and also\nthe interpolating functions used to estimate the ODE.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "tt = np.linspace(0., 5., 15)\nbeta = np.array([[0.,],\n                 [1.,]])\n\nfig1, ax1 = plt.subplots()\nfig2 = plt.figure()\nax2 = fig2.add_subplot(211)\nax3 = fig2.add_subplot(212)\n\n# plot the circle\ntheta = np.linspace(0., 2*np.pi, 100)\nx, y = np.cos(theta), np.sin(theta)\nax1.plot(x, y, 'k-', alpha=0.5)\n\n# simulate different realisations of the process\nfor symb in ['o', '^', 's']:\n    # random initioal condition for each sim.\n    x0 = np.random.normal(size=2)\n    x0 /= np.linalg.norm(x0)\n    Y, _ = mlfm.sim(x0, tt, beta)\n    ax1.plot(Y[:, 0], Y[:, 1], symb)\n    ax2.plot(tt, Y[:, 0], symb)\n    ax3.plot(tt, Y[:, 1], symb)\n\nax1.set_xlabel('$x$')\nax1.set_ylabel('$y$')\nax1.set_aspect('equal')\n\nax2.set_ylabel('$x$')\nax3.set_ylabel('$y$')\nax3.set_xlabel('time')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}